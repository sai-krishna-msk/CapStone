# Phase-1

- Creating basic dashboard



- Using a pre-trained Comprehension Model 
  - With base language Model(pre-trained wiki)
  - Task Specific pretrained on general dataset



- Using a pretrained Model for semantic Search
  - using a distill BERT model



- Scoring each paper



- Creating an ideal paper and finding out semantic similarity between that and this



# Phase 2

- Training a Doc2Vec model for operating systems (gensim)

- Train a hugging face language model 

- train the language model on specific dataset 